{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOPiSUwwHAYermPWz8iKzsc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/armaanranjan/Course_Compass/blob/main/Course_Recomender.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQgd4RPjOEk3",
        "outputId": "0a34381b-fa5d-4219-f1ce-28f40a97eeac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Dataset Summary:\n",
            "{'total_courses': 100, 'average_rating': 3.94, 'average_duration_hours': 26.25, 'level_distribution': {'Beginner': 28, 'All Levels': 27, 'Advanced': 23, 'Intermediate': 22}, 'rating_distribution': {Interval(2.9970000000000003, 3.4, closed='right'): 29, Interval(3.4, 3.8, closed='right'): 17, Interval(3.8, 4.2, closed='right'): 21, Interval(4.2, 4.6, closed='right'): 18, Interval(4.6, 5.0, closed='right'): 15}}\n",
            "\n",
            "Cleaned Dataset Sample:\n",
            "   course_idx             course_title  rating       level  duration_hours\n",
            "0           1         Course 0 - Basic     3.7    Advanced            97.0\n",
            "1           2      Course 1 - Advanced     4.9  All Levels             0.0\n",
            "2           3  Course 2 - Intermediate     4.5    Advanced            19.0\n",
            "3           4         Course 3 - Basic     4.2    Beginner             0.0\n",
            "4           5      Course 4 - Advanced     3.3  All Levels            53.0\n",
            "\n",
            "Dataset Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 100 entries, 0 to 99\n",
            "Data columns (total 5 columns):\n",
            " #   Column          Non-Null Count  Dtype  \n",
            "---  ------          --------------  -----  \n",
            " 0   course_idx      100 non-null    int64  \n",
            " 1   course_title    100 non-null    object \n",
            " 2   rating          100 non-null    float64\n",
            " 3   level           100 non-null    object \n",
            " 4   duration_hours  100 non-null    float64\n",
            "dtypes: float64(2), int64(1), object(2)\n",
            "memory usage: 4.0+ KB\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from scipy.sparse.linalg import svds\n",
        "import re\n",
        "\n",
        "class CourseDataCleaner:\n",
        "    def __init__(self):\n",
        "        self.df = '/content/CourseraDataset-Clean.csv'\n",
        "\n",
        "    def clean_duration(self, duration):\n",
        "        \"\"\"Convert duration strings to hours\"\"\"\n",
        "        try:\n",
        "            if pd.isna(duration):\n",
        "                return None\n",
        "\n",
        "            duration = str(duration).lower()\n",
        "            # Extract numbers\n",
        "            numbers = re.findall(r'\\d+\\.?\\d*', duration)\n",
        "            if not numbers:\n",
        "                return None\n",
        "\n",
        "            number = float(numbers[0])\n",
        "\n",
        "            # Convert to hours\n",
        "            if 'minute' in duration:\n",
        "                return round(number / 60, 1)\n",
        "            elif 'hour' in duration:\n",
        "                return round(number, 1)\n",
        "            else:\n",
        "                return None\n",
        "        except:\n",
        "            return None\n",
        "\n",
        "    def clean_level(self, level):\n",
        "        \"\"\"Standardize level categories\"\"\"\n",
        "        if pd.isna(level):\n",
        "            return 'Not Specified'\n",
        "\n",
        "        level = str(level).lower().strip()\n",
        "\n",
        "        if 'beginner' in level or 'basic' in level or 'fundamental' in level:\n",
        "            return 'Beginner'\n",
        "        elif 'intermediate' in level or 'medium' in level:\n",
        "            return 'Intermediate'\n",
        "        elif 'advanced' in level or 'expert' in level:\n",
        "            return 'Advanced'\n",
        "        elif 'all level' in level or 'all-level' in level:\n",
        "            return 'All Levels'\n",
        "        else:\n",
        "            return 'Not Specified'\n",
        "\n",
        "    def clean_rating(self, rating):\n",
        "        \"\"\"Clean and validate rating values\"\"\"\n",
        "        try:\n",
        "            rating = float(rating)\n",
        "            if 0 <= rating <= 5:\n",
        "                return round(rating, 1)\n",
        "            return None\n",
        "        except:\n",
        "            return None\n",
        "\n",
        "    def clean_course_title(self, title):\n",
        "        \"\"\"Clean course titles\"\"\"\n",
        "        if pd.isna(title):\n",
        "            return None\n",
        "\n",
        "        # Remove special characters and extra whitespace\n",
        "        title = re.sub(r'[^\\w\\s-]', ' ', str(title))\n",
        "        title = ' '.join(title.split())\n",
        "        return title.strip()\n",
        "\n",
        "    def clean_dataset(self, df):\n",
        "        \"\"\"\n",
        "        Clean the dataset with renamed columns\n",
        "\n",
        "        Parameters:\n",
        "        df: DataFrame with columns ['course_title', 'rating', 'level', 'duration']\n",
        "\n",
        "        Returns:\n",
        "        Cleaned DataFrame with standardized column names\n",
        "        \"\"\"\n",
        "        self.df = df.copy()\n",
        "\n",
        "        # Rename columns if they exist in their old format\n",
        "        column_mapping = {\n",
        "            'title': 'course_title',\n",
        "            'Duration to complete (Approx.)': 'duration',\n",
        "            'course_id': 'course_idx'\n",
        "        }\n",
        "\n",
        "        # Rename columns if they exist\n",
        "        for old_col, new_col in column_mapping.items():\n",
        "            if old_col in self.df.columns:\n",
        "                self.df = self.df.rename(columns={old_col: new_col})\n",
        "\n",
        "        # Clean individual columns\n",
        "        self.df['course_title'] = self.df['course_title'].apply(self.clean_course_title)\n",
        "        self.df['rating'] = self.df['rating'].apply(self.clean_rating)\n",
        "        self.df['level'] = self.df['level'].apply(self.clean_level)\n",
        "        self.df['duration_hours'] = self.df['duration'].apply(self.clean_duration)\n",
        "\n",
        "        # Drop rows with missing values\n",
        "        self.df = self.df.dropna(subset=['course_title'])  # Course title is required\n",
        "\n",
        "        # Fill missing values\n",
        "        self.df['rating'] = self.df['rating'].fillna(self.df['rating'].mean())\n",
        "        self.df['duration_hours'] = self.df['duration_hours'].fillna(self.df['duration_hours'].median())\n",
        "\n",
        "        # Drop the original duration column\n",
        "        self.df = self.df.drop('duration', axis=1)\n",
        "\n",
        "        # Add a course_idx column if it doesn't exist\n",
        "        if 'course_idx' not in self.df.columns:\n",
        "            self.df['course_idx'] = range(1, len(self.df) + 1)\n",
        "\n",
        "        # Ensure columns are in a consistent order\n",
        "        column_order = ['course_idx', 'course_title', 'rating', 'level', 'duration_hours']\n",
        "        self.df = self.df[column_order]\n",
        "\n",
        "        return self.df\n",
        "\n",
        "    def get_summary_stats(self):\n",
        "        \"\"\"Get summary statistics of the cleaned dataset\"\"\"\n",
        "        if self.df is None:\n",
        "            return \"No dataset has been cleaned yet.\"\n",
        "\n",
        "        stats = {\n",
        "            'total_courses': len(self.df),\n",
        "            'average_rating': round(self.df['rating'].mean(), 2),\n",
        "            'average_duration_hours': round(self.df['duration_hours'].mean(), 2),\n",
        "            'level_distribution': self.df['level'].value_counts().to_dict(),\n",
        "            'rating_distribution': self.df['rating'].value_counts(bins=5).sort_index().to_dict()\n",
        "        }\n",
        "\n",
        "        return stats\n",
        "\n",
        "# Example usage with sample data\n",
        "def create_sample_data(n_rows=100):\n",
        "    \"\"\"Create sample data with new column names\"\"\"\n",
        "    np.random.seed(42)\n",
        "\n",
        "    data = {\n",
        "        'course_title': [\n",
        "            f\"Course {i} - {'Basic' if i % 3 == 0 else 'Advanced' if i % 3 == 1 else 'Intermediate'}\"\n",
        "            for i in range(n_rows)\n",
        "        ],\n",
        "        'rating': np.random.uniform(3.0, 5.0, n_rows),\n",
        "        'level': np.random.choice(\n",
        "            ['Beginner', 'Intermediate', 'Advanced', 'All Levels'],\n",
        "            n_rows\n",
        "        ),\n",
        "        'duration': [\n",
        "            f\"{np.random.randint(1, 100)} {'hours' if i % 2 == 0 else 'minutes'}\"\n",
        "            for i in range(n_rows)\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    return pd.DataFrame(data)\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Create and clean sample data\n",
        "    sample_df = create_sample_data()\n",
        "    cleaner = CourseDataCleaner()\n",
        "    cleaned_df = cleaner.clean_dataset(sample_df)\n",
        "\n",
        "    # Print summary statistics\n",
        "    print(\"\\nDataset Summary:\")\n",
        "    print(cleaner.get_summary_stats())\n",
        "\n",
        "    # Display first few rows of cleaned data\n",
        "    print(\"\\nCleaned Dataset Sample:\")\n",
        "    print(cleaned_df.head())\n",
        "\n",
        "    # Display data info\n",
        "    print(\"\\nDataset Info:\")\n",
        "    print(cleaned_df.info())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from collections import defaultdict\n",
        "\n",
        "class CourseRecommender:\n",
        "    def __init__(self, cleaned_df):\n",
        "        \"\"\"\n",
        "        Initialize the recommender system with cleaned course data\n",
        "\n",
        "        Parameters:\n",
        "        cleaned_df: pandas DataFrame with columns ['course_title', 'rating', 'course_level', 'duration']\n",
        "        \"\"\"\n",
        "        self.df = cleaned_df\n",
        "        self.tfidf = TfidfVectorizer(stop_words='english')\n",
        "\n",
        "        # Create TF-IDF matrix for course titles\n",
        "        self.tfidf_matrix = self.tfidf.fit_transform(self.df['course_title'])\n",
        "\n",
        "        # Calculate similarity matrix\n",
        "        self.similarity_matrix = cosine_similarity(self.tfidf_matrix)\n",
        "\n",
        "        # Create level-based indices for faster filtering\n",
        "        self.level_indices = defaultdict(list)\n",
        "        for idx, level in enumerate(self.df['course_level']):\n",
        "            self.level_indices[level].append(idx)\n",
        "\n",
        "    def get_similar_courses(self, course_idx, n=5):\n",
        "        \"\"\"Get similar courses based on content similarity\"\"\"\n",
        "        course_similarities = self.similarity_matrix[course_idx]\n",
        "        similar_indices = course_similarities.argsort()[::-1][1:n+1]\n",
        "        return similar_indices\n",
        "\n",
        "    def collaborative_filtering(self, course_idx, n=5):\n",
        "        \"\"\"\n",
        "        Implement collaborative filtering based on course ratings\n",
        "        Returns courses with similar ratings patterns\n",
        "        \"\"\"\n",
        "        course_rating = self.df.iloc[course_idx]['rating']\n",
        "        rating_diff = abs(self.df['rating'] - course_rating)\n",
        "        similar_courses = rating_diff.sort_values().index[1:n+1]\n",
        "        return similar_courses\n",
        "\n",
        "    def keyword_search(self, keyword, preferred_level=None, n=10):\n",
        "        \"\"\"\n",
        "        Search for courses based on keyword and optional level preference\n",
        "\n",
        "        Parameters:\n",
        "        keyword: str - Search term\n",
        "        preferred_level: str - Preferred course level (optional)\n",
        "        n: int - Number of recommendations to return\n",
        "\n",
        "        Returns:\n",
        "        DataFrame with recommended courses\n",
        "        \"\"\"\n",
        "        # Convert keyword to TF-IDF vector\n",
        "        keyword_vector = self.tfidf.transform([keyword])\n",
        "\n",
        "        # Calculate similarity with all courses\n",
        "        similarities = cosine_similarity(keyword_vector, self.tfidf_matrix)[0]\n",
        "\n",
        "        # Create DataFrame with similarities\n",
        "        results = pd.DataFrame({\n",
        "            'index': range(len(similarities)),\n",
        "            'similarity': similarities,\n",
        "            'rating': self.df['rating'].values,\n",
        "            'level': self.df['course_level'].values\n",
        "        })\n",
        "\n",
        "        # Calculate combined score (similarity * rating)\n",
        "        results['combined_score'] = results['similarity'] * results['rating']\n",
        "\n",
        "        if preferred_level:\n",
        "            # Sort by level preference first, then by combined score\n",
        "            preferred_courses = results[results['level'] == preferred_level].sort_values(\n",
        "                'combined_score', ascending=False\n",
        "            )\n",
        "            other_courses = results[results['level'] != preferred_level].sort_values(\n",
        "                'combined_score', ascending=False\n",
        "            )\n",
        "            results = pd.concat([preferred_courses, other_courses])\n",
        "        else:\n",
        "            results = results.sort_values('combined_score', ascending=False)\n",
        "\n",
        "        # Get top N recommendations\n",
        "        top_indices = results['index'].head(n).values\n",
        "\n",
        "        # Return recommended courses\n",
        "        recommendations = self.df.iloc[top_indices].copy()\n",
        "        recommendations['similarity_score'] = results['similarity'].head(n).values\n",
        "        recommendations['combined_score'] = results['combined_score'].head(n).values\n",
        "\n",
        "        return recommendations.sort_values('combined_score', ascending=False)\n",
        "\n",
        "    def get_recommendations(self, query, preferred_level=None, n=10):\n",
        "        \"\"\"\n",
        "        Main recommendation function combining all approaches\n",
        "\n",
        "        Parameters:\n",
        "        query: str - Search query\n",
        "        preferred_level: str - Preferred course level (optional)\n",
        "        n: int - Number of recommendations\n",
        "\n",
        "        Returns:\n",
        "        DataFrame with recommended courses\n",
        "        \"\"\"\n",
        "        # Get initial recommendations based on keyword search\n",
        "        recommendations = self.keyword_search(query, preferred_level, n)\n",
        "\n",
        "        # For the top result, get similar courses based on content\n",
        "        if len(recommendations) > 0:\n",
        "            top_course_idx = recommendations.index[0]\n",
        "            similar_courses = self.get_similar_courses(top_course_idx, n=5)\n",
        "\n",
        "            # Add collaborative filtering recommendations\n",
        "            collab_courses = self.collaborative_filtering(top_course_idx, n=5)\n",
        "\n",
        "            # Combine all recommendations\n",
        "            additional_courses = pd.Index(np.concatenate([similar_courses, collab_courses]))\n",
        "            additional_df = self.df.loc[additional_courses].copy()\n",
        "\n",
        "            # If preferred level is specified, prioritize those courses\n",
        "            if preferred_level:\n",
        "                level_mask = additional_df['course_level'] == preferred_level\n",
        "                additional_df = pd.concat([\n",
        "                    additional_df[level_mask],\n",
        "                    additional_df[~level_mask]\n",
        "                ])\n",
        "\n",
        "            # Combine and remove duplicates\n",
        "            recommendations = pd.concat([recommendations, additional_df]).drop_duplicates(\n",
        "                subset=['course_title']\n",
        "            ).head(n)\n",
        "\n",
        "        return recommendations\n",
        "\n",
        "# Example usage\n",
        "def demonstrate_recommender(cleaned_df):\n",
        "    \"\"\"\n",
        "    Demonstrate how to use the recommender system\n",
        "    \"\"\"\n",
        "    # Initialize recommender\n",
        "    recommender = CourseRecommender(cleaned_df)\n",
        "\n",
        "    # Example searches\n",
        "    print(\"Search for 'python' courses (all levels):\")\n",
        "    results = recommender.get_recommendations('python')\n",
        "    print(results[['course_title', 'rating', 'course_level', 'duration', 'combined_score']])\n",
        "\n",
        "    print(\"\\nSearch for 'python' courses (Beginner level):\")\n",
        "    results = recommender.get_recommendations('python', preferred_level='Beginner')\n",
        "    print(results[['course_title', 'rating', 'course_level', 'duration', 'combined_score']])"
      ],
      "metadata": {
        "id": "NIfMjyOcyjeE"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from scipy.sparse import csr_matrix\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "class CourseRecommender:\n",
        "    def __init__(self, cleaned_df):\n",
        "        self.df = cleaned_df\n",
        "        self.tfidf = TfidfVectorizer(stop_words='english')\n",
        "\n",
        "        # Create TF-IDF matrix for content-based filtering\n",
        "        self.tfidf_matrix = self.tfidf.fit_transform(self.df['course_title'])\n",
        "        self.content_similarity = cosine_similarity(self.tfidf_matrix)\n",
        "\n",
        "        # Create user-item matrix for collaborative filtering\n",
        "        # For this example, we'll use course ratings as implicit feedback\n",
        "        self.course_rating_matrix = csr_matrix((\n",
        "            np.ones(len(self.df)),  # Assuming each course has been taken at least once\n",
        "            (\n",
        "                np.arange(len(self.df)),  # Course indices\n",
        "                self.df['course_idx'].values\n",
        "            )\n",
        "        ))\n",
        "\n",
        "        # Initialize collaborative filtering model\n",
        "        self.cf_model = NearestNeighbors(metric='cosine', algorithm='brute')\n",
        "        self.cf_model.fit(self.course_rating_matrix)\n",
        "\n",
        "    def search_courses(self, keyword, level=None, top_n=10):\n",
        "        \"\"\"\n",
        "        Search courses based on keyword and level preference\n",
        "        \"\"\"\n",
        "        # Convert keyword to lowercase for case-insensitive search\n",
        "        keyword = keyword.lower()\n",
        "\n",
        "        # Filter courses that contain the keyword\n",
        "        mask = self.df['course_title'].str.lower().str.contains(keyword)\n",
        "        matching_courses = self.df[mask].copy()\n",
        "\n",
        "        if matching_courses.empty:\n",
        "            return pd.DataFrame()\n",
        "\n",
        "        # Sort by level preference if specified\n",
        "        if level:\n",
        "            # Put preferred level courses first\n",
        "            matching_courses['level_match'] = (matching_courses['level'] == level).astype(int)\n",
        "            matching_courses = matching_courses.sort_values(\n",
        "                by=['level_match', 'rating'],\n",
        "                ascending=[False, False]\n",
        "            )\n",
        "        else:\n",
        "            # Sort by rating only\n",
        "            matching_courses = matching_courses.sort_values('rating', ascending=False)\n",
        "\n",
        "        return matching_courses.head(top_n)\n",
        "\n",
        "    def get_content_based_recommendations(self, course_idx, top_n=5):\n",
        "        \"\"\"\n",
        "        Get content-based recommendations based on course similarity\n",
        "        \"\"\"\n",
        "        course_row = self.df[self.df['course_idx'] == course_idx].index[0]\n",
        "        similar_scores = self.content_similarity[course_row]\n",
        "        similar_courses = list(enumerate(similar_scores))\n",
        "\n",
        "        # Sort by similarity score\n",
        "        similar_courses = sorted(similar_courses, key=lambda x: x[1], reverse=True)\n",
        "        similar_courses = similar_courses[1:top_n+1]  # Exclude the input course\n",
        "\n",
        "        course_indices = [i[0] for i in similar_courses]\n",
        "        return self.df.iloc[course_indices]\n",
        "\n",
        "    def get_collaborative_recommendations(self, course_idx, top_n=5):\n",
        "        \"\"\"\n",
        "        Get collaborative filtering recommendations based on course ratings\n",
        "        \"\"\"\n",
        "        course_row = self.df[self.df['course_idx'] == course_idx].index[0]\n",
        "        distances, indices = self.cf_model.kneighbors(\n",
        "            self.course_rating_matrix[course_row].toarray().reshape(1, -1),\n",
        "            n_neighbors=top_n+1\n",
        "        )\n",
        "\n",
        "        # Exclude the input course\n",
        "        similar_course_indices = indices.flatten()[1:]\n",
        "        return self.df.iloc[similar_course_indices]\n",
        "\n",
        "    def get_hybrid_recommendations(self, keyword, level=None, course_idx=None, top_n=10):\n",
        "        \"\"\"\n",
        "        Get hybrid recommendations combining keyword search, content-based, and collaborative filtering\n",
        "        \"\"\"\n",
        "        # Get initial keyword-based results\n",
        "        keyword_results = self.search_courses(keyword, level, top_n=top_n)\n",
        "\n",
        "        if course_idx is not None:\n",
        "            # Get content-based and collaborative recommendations\n",
        "            content_recommendations = self.get_content_based_recommendations(course_idx, top_n=top_n)\n",
        "            collab_recommendations = self.get_collaborative_recommendations(course_idx, top_n=top_n)\n",
        "\n",
        "            # Combine all recommendations\n",
        "            all_recommendations = pd.concat([\n",
        "                keyword_results,\n",
        "                content_recommendations,\n",
        "                collab_recommendations\n",
        "            ]).drop_duplicates(subset=['course_idx'])\n",
        "\n",
        "            # Sort by level preference if specified\n",
        "            if level:\n",
        "                all_recommendations['level_match'] = (all_recommendations['level'] == level).astype(int)\n",
        "                all_recommendations = all_recommendations.sort_values(\n",
        "                    by=['level_match', 'rating'],\n",
        "                    ascending=[False, False]\n",
        "                )\n",
        "            else:\n",
        "                all_recommendations = all_recommendations.sort_values('rating', ascending=False)\n",
        "\n",
        "            return all_recommendations.head(top_n)\n",
        "\n",
        "        return keyword_results\n",
        "\n",
        "# Example usage\n",
        "def demonstrate_recommender(cleaned_df):\n",
        "    # Initialize the recommender\n",
        "    recommender = CourseRecommender(cleaned_df)\n",
        "\n",
        "    # Example 1: Search courses with keyword\n",
        "    print(\"Searching for 'python' courses:\")\n",
        "    python_courses = recommender.search_courses('python')\n",
        "    print(python_courses[['course_title', 'level', 'rating']])\n",
        "\n",
        "    # Example 2: Search with level preference\n",
        "    print(\"\\nSearching for 'python' courses (Beginner level preferred):\")\n",
        "    python_beginner = recommender.search_courses('python', level='Beginner')\n",
        "    print(python_beginner[['course_title', 'level', 'rating']])\n",
        "\n",
        "    # Example 3: Get hybrid recommendations\n",
        "    print(\"\\nHybrid recommendations for 'python' with course_idx=1:\")\n",
        "    hybrid_recommendations = recommender.get_hybrid_recommendations(\n",
        "        keyword='python',\n",
        "        level='Beginner',\n",
        "        course_idx=1\n",
        "    )\n",
        "    print(hybrid_recommendations[['course_title', 'level', 'rating']])\n",
        "\n",
        "# Run the demonstration\n",
        "# demonstrate_recommender(cleaned_df)"
      ],
      "metadata": {
        "id": "B1t-j5UiHhRw"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, precision_score, recall_score, ndcg_score\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from scipy.sparse import csr_matrix\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "class CourseRecommender:\n",
        "    def __init__(self, cleaned_df):\n",
        "        if cleaned_df.empty:\n",
        "            raise ValueError(\"The input DataFrame is empty\")\n",
        "\n",
        "        self.df = cleaned_df.copy()\n",
        "        self.df = self.df.reset_index(drop=True)  # Reset index to avoid any gaps\n",
        "\n",
        "        # Validate required columns\n",
        "        required_columns = ['course_idx', 'course_title', 'rating', 'level', 'duration_hours']\n",
        "        missing_columns = [col for col in required_columns if col not in self.df.columns]\n",
        "        if missing_columns:\n",
        "            raise ValueError(f\"Missing required columns: {missing_columns}\")\n",
        "\n",
        "        # Initialize TF-IDF\n",
        "        self.tfidf = TfidfVectorizer(stop_words='english')\n",
        "\n",
        "        try:\n",
        "            # Create TF-IDF matrix for content-based filtering\n",
        "            self.tfidf_matrix = self.tfidf.fit_transform(self.df['course_title'].astype(str))\n",
        "            self.content_similarity = cosine_similarity(self.tfidf_matrix)\n",
        "\n",
        "            # Create user-item matrix for collaborative filtering\n",
        "            self.course_rating_matrix = csr_matrix((\n",
        "                np.ones(len(self.df)),\n",
        "                (\n",
        "                    np.arange(len(self.df)),\n",
        "                    self.df['course_idx'].values\n",
        "                )\n",
        "            ))\n",
        "\n",
        "            # Initialize collaborative filtering model\n",
        "            self.cf_model = NearestNeighbors(metric='cosine', algorithm='brute')\n",
        "            self.cf_model.fit(self.course_rating_matrix)\n",
        "\n",
        "        except Exception as e:\n",
        "            raise ValueError(f\"Error initializing recommender: {str(e)}\")\n",
        "\n",
        "    def search_courses(self, keyword, level=None, top_n=10):\n",
        "        \"\"\"\n",
        "        Search courses based on keyword and level preference\n",
        "        \"\"\"\n",
        "        if not isinstance(keyword, str):\n",
        "            raise ValueError(\"Keyword must be a string\")\n",
        "\n",
        "        # Convert keyword to lowercase for case-insensitive search\n",
        "        keyword = keyword.lower()\n",
        "\n",
        "        # Filter courses that contain the keyword\n",
        "        mask = self.df['course_title'].str.lower().str.contains(keyword)\n",
        "        matching_courses = self.df[mask].copy()\n",
        "\n",
        "        if matching_courses.empty:\n",
        "            print(f\"No courses found matching keyword: {keyword}\")\n",
        "            return pd.DataFrame(columns=self.df.columns)\n",
        "\n",
        "        # Sort by level preference if specified\n",
        "        if level:\n",
        "            matching_courses['level_match'] = (matching_courses['level'] == level).astype(int)\n",
        "            matching_courses = matching_courses.sort_values(\n",
        "                by=['level_match', 'rating'],\n",
        "                ascending=[False, False]\n",
        "            )\n",
        "        else:\n",
        "            matching_courses = matching_courses.sort_values('rating', ascending=False)\n",
        "\n",
        "        return matching_courses.head(top_n)\n",
        "\n",
        "    def get_content_based_recommendations(self, course_idx, top_n=5):\n",
        "        \"\"\"\n",
        "        Get content-based recommendations based on course similarity\n",
        "        \"\"\"\n",
        "        try:\n",
        "            course_row = self.df[self.df['course_idx'] == course_idx].index[0]\n",
        "            similar_scores = self.content_similarity[course_row]\n",
        "            similar_courses = list(enumerate(similar_scores))\n",
        "\n",
        "            # Sort by similarity score\n",
        "            similar_courses = sorted(similar_courses, key=lambda x: x[1], reverse=True)\n",
        "            similar_courses = similar_courses[1:top_n+1]  # Exclude the input course\n",
        "\n",
        "            course_indices = [i[0] for i in similar_courses]\n",
        "            return self.df.iloc[course_indices]\n",
        "        except IndexError:\n",
        "            print(f\"Course index {course_idx} not found\")\n",
        "            return pd.DataFrame(columns=self.df.columns)\n",
        "\n",
        "class CourseRecommenderTrainer:\n",
        "    def __init__(self, cleaned_df):\n",
        "        # Validate input data\n",
        "        if not isinstance(cleaned_df, pd.DataFrame):\n",
        "            raise ValueError(\"Input must be a pandas DataFrame\")\n",
        "\n",
        "        if cleaned_df.empty:\n",
        "            raise ValueError(\"Input DataFrame is empty\")\n",
        "\n",
        "        self.df = cleaned_df.copy()\n",
        "        self.train_data = None\n",
        "        self.test_data = None\n",
        "        self.recommender = None\n",
        "\n",
        "    def prepare_data(self, test_size=0.2, random_state=42):\n",
        "        \"\"\"\n",
        "        Prepare training and testing datasets\n",
        "        \"\"\"\n",
        "        if len(self.df) < 2:\n",
        "            raise ValueError(\"Dataset must contain at least 2 samples for train-test split\")\n",
        "\n",
        "        try:\n",
        "            # Split the data into training and testing sets\n",
        "            self.train_data, self.test_data = train_test_split(\n",
        "                self.df,\n",
        "                test_size=test_size,\n",
        "                random_state=random_state,\n",
        "                stratify=self.df['level'] if len(self.df['level'].unique()) > 1 else None\n",
        "            )\n",
        "\n",
        "            # Initialize and train the recommender with training data\n",
        "            self.recommender = CourseRecommender(self.train_data)\n",
        "\n",
        "            print(f\"Training set size: {len(self.train_data)}\")\n",
        "            print(f\"Testing set size: {len(self.test_data)}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            raise ValueError(f\"Error preparing data: {str(e)}\")\n",
        "\n",
        "# Function to validate and preprocess the dataset\n",
        "def preprocess_dataset(df):\n",
        "    \"\"\"\n",
        "    Validate and preprocess the input dataset\n",
        "    \"\"\"\n",
        "    # Check if DataFrame is empty\n",
        "    if df.empty:\n",
        "        raise ValueError(\"Input DataFrame is empty\")\n",
        "\n",
        "    # Check required columns\n",
        "    required_columns = ['course_idx', 'course_title', 'rating', 'level', 'duration_hours']\n",
        "    missing_columns = [col for col in required_columns if col not in df.columns]\n",
        "    if missing_columns:\n",
        "        raise ValueError(f\"Missing required columns: {missing_columns}\")\n",
        "\n",
        "    # Create a copy of the DataFrame\n",
        "    cleaned_df = df.copy()\n",
        "\n",
        "    # Reset index\n",
        "    cleaned_df = cleaned_df.reset_index(drop=True)\n",
        "\n",
        "    # Convert course_title to string\n",
        "    cleaned_df['course_title'] = cleaned_df['course_title'].astype(str)\n",
        "\n",
        "    # Convert rating to float\n",
        "    cleaned_df['rating'] = pd.to_numeric(cleaned_df['rating'], errors='coerce')\n",
        "\n",
        "    # Convert duration_hours to float\n",
        "    cleaned_df['duration_hours'] = pd.to_numeric(cleaned_df['duration_hours'], errors='coerce')\n",
        "\n",
        "    # Remove rows with missing values\n",
        "    cleaned_df = cleaned_df.dropna()\n",
        "\n",
        "    return cleaned_df\n",
        "\n",
        "def train_and_evaluate_recommender(df):\n",
        "    \"\"\"\n",
        "    Complete training and evaluation pipeline with error handling\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Preprocess the dataset\n",
        "        print(\"Preprocessing dataset...\")\n",
        "        cleaned_df = preprocess_dataset(df)\n",
        "\n",
        "        # Initialize trainer\n",
        "        print(\"Initializing trainer...\")\n",
        "        trainer = CourseRecommenderTrainer(cleaned_df)\n",
        "\n",
        "        # Prepare data\n",
        "        print(\"Preparing data...\")\n",
        "        trainer.prepare_data()\n",
        "\n",
        "        return trainer\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error in training pipeline: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "# Example usage\n",
        "\n",
        "# Assuming your DataFrame is called 'cleaned_df'\n",
        "# First, let's check the data\n",
        "print(\"Dataset shape:\", cleaned_df.shape)\n",
        "print(\"\\nDataset columns:\", cleaned_df.columns.tolist())\n",
        "print(\"\\nSample of the data:\")\n",
        "print(cleaned_df.head())\n",
        "\n",
        "# Train the recommender\n",
        "trainer = train_and_evaluate_recommender(cleaned_df)\n",
        "\n",
        "if trainer is not None:\n",
        "    # Get recommendations for a specific course\n",
        "    recommender = trainer.recommender\n",
        "    recommendations = recommender.search_courses(\n",
        "        keyword=\"Fashion\",\n",
        "        level=\"Beginner\"\n",
        "    )\n",
        "    print(\"\\nSample recommendations:\")\n",
        "    print(recommendations[['course_title', 'level', 'rating']])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WqWDX-sKo3Xw",
        "outputId": "5cead236-d4c3-41e9-c7ff-d4fa23e4022b"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset shape: (100, 5)\n",
            "\n",
            "Dataset columns: ['course_idx', 'course_title', 'rating', 'level', 'duration_hours']\n",
            "\n",
            "Sample of the data:\n",
            "   course_idx             course_title  rating       level  duration_hours\n",
            "0           1         Course 0 - Basic     3.7    Advanced            97.0\n",
            "1           2      Course 1 - Advanced     4.9  All Levels             0.0\n",
            "2           3  Course 2 - Intermediate     4.5    Advanced            19.0\n",
            "3           4         Course 3 - Basic     4.2    Beginner             0.0\n",
            "4           5      Course 4 - Advanced     3.3  All Levels            53.0\n",
            "Preprocessing dataset...\n",
            "Initializing trainer...\n",
            "Preparing data...\n",
            "Training set size: 80\n",
            "Testing set size: 20\n",
            "No courses found matching keyword: fashion\n",
            "\n",
            "Sample recommendations:\n",
            "Empty DataFrame\n",
            "Columns: [course_title, level, rating]\n",
            "Index: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "  import pandas as pd\n",
        "  import numpy as np\n",
        "  from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "  from sklearn.metrics.pairwise import cosine_similarity\n",
        "  from scipy.sparse import csr_matrix\n",
        "  from sklearn.neighbors import NearestNeighbors\n",
        "  import re\n",
        "\n",
        "  class CourseRecommender:\n",
        "      def __init__(self, cleaned_df):\n",
        "          if cleaned_df.empty:\n",
        "              raise ValueError(\"The input DataFrame is empty\")\n",
        "\n",
        "          self.df = cleaned_df.copy()\n",
        "          self.df = self.df.reset_index(drop=True)\n",
        "\n",
        "          # Create a normalized version of course titles for better searching\n",
        "          self.df['normalized_title'] = self.df['course_title'].apply(self.normalize_text)\n",
        "\n",
        "          # Initialize TF-IDF\n",
        "          self.tfidf = TfidfVectorizer(stop_words='english')\n",
        "\n",
        "          try:\n",
        "              # Create TF-IDF matrix for content-based filtering\n",
        "              self.tfidf_matrix = self.tfidf.fit_transform(self.df['course_title'].astype(str))\n",
        "              self.content_similarity = cosine_similarity(self.tfidf_matrix)\n",
        "\n",
        "              # Create user-item matrix for collaborative filtering\n",
        "              self.course_rating_matrix = csr_matrix((\n",
        "                  np.ones(len(self.df)),\n",
        "                  (\n",
        "                      np.arange(len(self.df)),\n",
        "                      self.df['course_idx'].values\n",
        "                  )\n",
        "              ))\n",
        "\n",
        "              # Initialize collaborative filtering model\n",
        "              self.cf_model = NearestNeighbors(metric='cosine', algorithm='brute')\n",
        "              self.cf_model.fit(self.course_rating_matrix)\n",
        "\n",
        "          except Exception as e:\n",
        "              raise ValueError(f\"Error initializing recommender: {str(e)}\")\n",
        "\n",
        "      @staticmethod\n",
        "      def normalize_text(text):\n",
        "          \"\"\"\n",
        "          Normalize text for better matching:\n",
        "          - Convert to lowercase\n",
        "          - Remove special characters\n",
        "          - Remove extra spaces\n",
        "          \"\"\"\n",
        "          if not isinstance(text, str):\n",
        "              text = str(text)\n",
        "\n",
        "          # Convert to lowercase\n",
        "          text = text.lower()\n",
        "          # Remove special characters and extra spaces\n",
        "          text = re.sub(r'[^\\w\\s]', ' ', text)\n",
        "          # Remove extra whitespace\n",
        "          text = ' '.join(text.split())\n",
        "          return text\n",
        "\n",
        "      def search_courses(self, keyword, level=None, top_n=10):\n",
        "          \"\"\"\n",
        "          Enhanced search function with multiple matching methods\n",
        "          \"\"\"\n",
        "          if not isinstance(keyword, str):\n",
        "              raise ValueError(\"Keyword must be a string\")\n",
        "\n",
        "          # Normalize the search keyword\n",
        "          normalized_keyword = self.normalize_text(keyword)\n",
        "\n",
        "          # Create different matching criteria\n",
        "          matches = pd.Series(False, index=self.df.index)\n",
        "\n",
        "          # 1. Exact match in normalized title\n",
        "          matches |= self.df['normalized_title'].str.contains(normalized_keyword, case=False, na=False)\n",
        "\n",
        "          # 2. Partial word matches\n",
        "          keyword_parts = normalized_keyword.split()\n",
        "          for part in keyword_parts:\n",
        "              if len(part) >= 3:  # Only search for parts with 3 or more characters\n",
        "                  matches |= self.df['normalized_title'].str.contains(part, case=False, na=False)\n",
        "\n",
        "          # 3. Use TF-IDF similarity for fuzzy matching if no direct matches found\n",
        "          if not matches.any():\n",
        "              # Transform the keyword using the fitted TF-IDF vectorizer\n",
        "              keyword_vector = self.tfidf.transform([keyword])\n",
        "              # Calculate similarity with all courses\n",
        "              similarities = cosine_similarity(keyword_vector, self.tfidf_matrix)[0]\n",
        "              # Get courses with similarity above threshold\n",
        "              similarity_threshold = 0.1  # Adjust this threshold as needed\n",
        "              matches = similarities > similarity_threshold\n",
        "\n",
        "          # Get matching courses\n",
        "          matching_courses = self.df[matches].copy()\n",
        "\n",
        "          # If still no matches found, return empty DataFrame with proper columns\n",
        "          if matching_courses.empty:\n",
        "              print(f\"No courses found matching keyword: {keyword}\")\n",
        "              return pd.DataFrame(columns=self.df.columns)\n",
        "\n",
        "          # Calculate similarity scores for ranking\n",
        "          if len(matching_courses) > 0:\n",
        "              keyword_vector = self.tfidf.transform([keyword])\n",
        "              matching_courses['similarity_score'] = cosine_similarity(\n",
        "                  keyword_vector,\n",
        "                  self.tfidf.transform(matching_courses['course_title'])\n",
        "              )[0]\n",
        "\n",
        "          # Sort by level preference and similarity score\n",
        "          if level:\n",
        "              matching_courses['level_match'] = (matching_courses['level'] == level).astype(int)\n",
        "              matching_courses = matching_courses.sort_values(\n",
        "                  by=['level_match', 'similarity_score', 'rating'],\n",
        "                  ascending=[False, False, False]\n",
        "              )\n",
        "          else:\n",
        "              matching_courses = matching_courses.sort_values(\n",
        "                  by=['similarity_score', 'rating'],\n",
        "                  ascending=[False, False]\n",
        "              )\n",
        "\n",
        "          # Remove temporary columns used for sorting\n",
        "          matching_courses = matching_courses.drop(columns=['similarity_score', 'normalized_title'])\n",
        "          if level:\n",
        "              matching_courses = matching_courses.drop(columns=['level_match'])\n",
        "\n",
        "          return matching_courses.head(top_n)\n",
        "\n",
        "      def get_content_based_recommendations(self, course_idx, top_n=5):\n",
        "          \"\"\"\n",
        "          Get content-based recommendations based on course similarity\n",
        "          \"\"\"\n",
        "          try:\n",
        "              course_row = self.df[self.df['course_idx'] == course_idx].index[0]\n",
        "              similar_scores = self.content_similarity[course_row]\n",
        "              similar_courses = list(enumerate(similar_scores))\n",
        "\n",
        "              # Sort by similarity score\n",
        "              similar_courses = sorted(similar_courses, key=lambda x: x[1], reverse=True)\n",
        "              similar_courses = similar_courses[1:top_n+1]  # Exclude the input course\n",
        "\n",
        "              course_indices = [i[0] for i in similar_courses]\n",
        "              return self.df.iloc[course_indices]\n",
        "          except IndexError:\n",
        "              print(f\"Course index {course_idx} not found\")\n",
        "              return pd.DataFrame(columns=self.df.columns)\n",
        "\n",
        "  # Example usage function\n",
        "  def test_course_search(cleaned_df, keyword, level=None):\n",
        "      \"\"\"\n",
        "      Test the course search functionality with detailed output\n",
        "      \"\"\"\n",
        "      print(f\"\\nTesting search for keyword: '{keyword}' with level: {level}\")\n",
        "      print(\"-\" * 50)\n",
        "\n",
        "      # Initialize recommender\n",
        "      recommender = CourseRecommender(cleaned_df)\n",
        "\n",
        "      # Perform search\n",
        "      results = recommender.search_courses(keyword, level=level)\n",
        "\n",
        "      # Display results\n",
        "      if not results.empty:\n",
        "          print(f\"\\nFound {len(results)} matching courses:\")\n",
        "          print(\"\\nTop matching courses:\")\n",
        "          for idx, row in results.iterrows():\n",
        "              print(f\"\\nTitle: {row['course_title']}\")\n",
        "              print(f\"Level: {row['level']}\")\n",
        "              print(f\"Rating: {row['rating']}\")\n",
        "              print(\"-\" * 30)\n",
        "      else:\n",
        "          print(\"No matching courses found.\")\n",
        "\n",
        "      return results\n",
        "\n",
        "  # Test the search functionality\n",
        "\n",
        "  # Test with your dataset\n",
        "  print(\"Testing search functionality...\")\n",
        "\n",
        "  # Example 1: Basic search\n",
        "  results1 = test_course_search(cleaned_df, \"Python\")\n",
        "\n",
        "  # Example 2: Search with level preference\n",
        "  results2 = test_course_search(cleaned_df, \"Python \", level=\"Beginner\")\n",
        "\n",
        "  # Example 3: Search with partial match\n",
        "  results3 = test_course_search(cleaned_df, \"data science\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tszKUrd8u41r",
        "outputId": "5dd6d5ff-47e0-4d79-ce1d-6d51a3ecdc73"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing search functionality...\n",
            "\n",
            "Testing search for keyword: 'Python' with level: None\n",
            "--------------------------------------------------\n",
            "No courses found matching keyword: Python\n",
            "No matching courses found.\n",
            "\n",
            "Testing search for keyword: 'Python ' with level: Beginner\n",
            "--------------------------------------------------\n",
            "No courses found matching keyword: Python \n",
            "No matching courses found.\n",
            "\n",
            "Testing search for keyword: 'data science' with level: None\n",
            "--------------------------------------------------\n",
            "No courses found matching keyword: data science\n",
            "No matching courses found.\n"
          ]
        }
      ]
    }
  ]
}